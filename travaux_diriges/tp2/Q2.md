# 2. Produit matrice-vecteur parallèle

Dans cet exercice, deux stratégies de décomposition ont été comparées pour le calcul du produit  
\( v = A \cdot u \), avec une matrice de dimension \( N = 4800 \).

---

## a – Produit parallèle par colonnes

## Description de l’approche
La matrice \( A \) est découpée verticalement. Chaque processus stocke un bloc de  
\( N_{loc} = N / nbp \) colonnes.

- Chaque processus calcule une contribution partielle au vecteur résultat.
- Une opération de réduction globale (`MPI_Allreduce`) est utilisée pour sommer les contributions locales et obtenir le vecteur final.

## Résultats expérimentaux

| Nombre de processus | Temps d'exécution (Tₚ) | Speedup (S = T₁ / Tₚ) |
| :---: | :---: | :---: |
| 1 | 0.00526 s | 1.00 |
| 2 | 0.00402 s | 1.31 |
| 4 | 0.00306 s | 1.72 |

## Interprétation
Le speedup reste limité (1.72 pour 4 cœurs) et l’accélération n’est pas linéaire. Cela s’explique par la granularité fine du problème : le temps de calcul est très court, de l’ordre de quelques millisecondes. Dans ce contexte, le coût des communications MPI, en particulier l’appel à `MPI_Allreduce`, représente une part significative du temps total d’exécution.

---

## b – Produit parallèle par lignes

## Description de l’approche
La matrice \( A \) est découpée horizontalement. Chaque processus stocke un bloc de  
\( N_{loc} = N / nbp \) lignes.

- Chaque processus calcule un segment complet du vecteur résultat final.
- Une opération de rassemblement (`MPI_Allgather`) est utilisée pour reconstruire le vecteur complet sur tous les processus.

## Résultats expérimentaux

| Nombre de processus | Temps d'exécution (Tₚ) | Speedup (S = T₁ / Tₚ) |
| :---: | :---: | :---: |
| 1 | 0.01029 s | 1.00 |
| 2 | 0.00630 s | 1.63 |
| 4 | 0.00836 s | 1.23 |

## Analyse et comparaison

### 1. Dégradation des performances pour 4 processus
Avec la décomposition par lignes, on observe une augmentation du temps d’exécution lors du passage de 2 à 4 processus. Pour cette taille de problème (\( N = 4800 \)), le coût de communication de l’opération `MPI_Allgather`, qui implique l’échange de volumes de données importants entre tous les processus, devient supérieur au gain apporté par la division du calcul. Le rapport calcul/communication est donc défavorable.

### 2. Comparaison entre décomposition par lignes et par colonnes
Dans ces expériences, la décomposition par colonnes s’est révélée plus efficace, avec un temps de référence plus faible et un meilleur passage à l’échelle.

À noter que, bien que les bibliothèques numériques soient généralement optimisées pour des accès mémoire par lignes, le coût relatif des primitives MPI utilisées (`Allreduce` contre `Allgather`) et l’implémentation retenue sur cette machine ont favorisé l’approche par colonnes.

## Conclusion
Pour des opérations matricielles denses dont le temps de calcul est très court, le parallélisme n’apporte pas systématiquement un gain de performance. Lorsque la taille du problème est insuffisante, le coût des communications MPI peut dominer le temps total d’exécution et limiter, voire annuler, les bénéfices du calcul parallèle.
