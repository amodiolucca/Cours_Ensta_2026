# 1. Parallélisation par partition équitable par blocs

## Résultats expérimentaux

Les mesures de temps ont été effectuées sur une grille de 1024 × 1024 pixels.

| Nombre de processus (N) | Temps d'exécution (Tₚ) | Speedup (S = T₁ / Tₚ) | Efficacité (E = S / N) |
| :---: | :---: | :---: | :---: |
| 1 | 1.253 s | 1.00 | 100 % |
| 2 | 0.638 s | 1.96 | 98 % |
| 4 | 0.368 s | 3.40 | 85 % |

## Interprétation des résultats

### 1. Analyse de la performance
On observe une accélération globale du programme. Avec 2 processus, le speedup est proche de l’idéal théorique. En revanche, lorsque l’on passe à 4 processus, l’efficacité diminue (S = 3.40, efficacité de 85 %). L’accélération n’est donc plus linéaire.

### 2. Déséquilibre de charge
Cette perte d’efficacité s’explique par la nature irrégulière du calcul de l’ensemble de Mandelbrot.

- Les pixels situés au centre de l’image, appartenant à l’ensemble, nécessitent le nombre maximal d’itérations (max_iterations = 50).
- Les pixels situés en périphérie divergent rapidement et demandent peu de calculs.

### 3. Limite de la partition par blocs
Avec une partition statique par blocs de lignes contiguës :

- Les processus chargés des bandes centrales de l’image reçoivent une charge de calcul plus importante que ceux traitant les bords supérieur et inférieur.
- Comme l’opération MPI_Gather est synchronisante, le temps total d’exécution est déterminé par le processus le plus lent. Les autres processus terminent plus tôt et restent inactifs, ce qui dégrade la performance globale.

---

# 2. Répartition statique améliorée : distribution cyclique

## Résultats expérimentaux

Le calcul a été relancé avec une distribution cyclique des lignes (le processus 0 traite les lignes 0, 4, 8, … ; le processus 1 traite les lignes 1, 5, 9, …).

| Méthode | Temps (4 processus) | Speedup (S) | Efficacité (E) |
| :--- | :---: | :---: | :---: |
| Partition par blocs (Q1) | 0.368 s | 3.40 | 85 % |
| Partition cyclique (Q2) | 0.348 s | 3.60 | 90 % |

Temps de référence séquentiel : 1.253 s.

## Interprétation

### 1. Amélioration du speedup
La distribution cyclique permet une amélioration mesurable des performances. Le speedup atteint 3.60, se rapprochant davantage de la valeur idéale de 4.

### 2. Répartition de la charge
Contrairement à la partition par blocs, où certains processus se retrouvaient majoritairement dans la zone centrale de l’image (plus coûteuse en calcul), la distribution cyclique impose à chaque processus de traiter à la fois des lignes coûteuses et des lignes peu coûteuses.

Ce mélange conduit à une répartition de la charge plus homogène entre les processus.

## Limites de la stratégie
Malgré cette amélioration, la stratégie reste statique.

Si le nombre de processus augmente fortement ou si l’on effectue un zoom sur une région particulière de la fractale, un déséquilibre peut réapparaître. Par ailleurs, cette approche ne tient pas compte de l’hétérogénéité du matériel : un processus plus lent ralentira l’ensemble du calcul, la charge de travail étant fixée dès le départ.

---

# 3. Stratégie maître-esclave (équilibrage dynamique)

## Description de l’approche
La dernière méthode repose sur une architecture maître-esclave afin de corriger les limites des répartitions statiques.

- Le maître (rang 0) ne réalise pas de calcul intensif. Il maintient une file de tâches correspondant aux indices des lignes (y = 0 à 1023) et les distribue dynamiquement aux processus disponibles.
- Les esclaves (rang > 0) demandent une tâche, calculent la ligne correspondante, renvoient le résultat au maître, puis demandent immédiatement une nouvelle tâche.

Pour réduire le temps de calcul local, une version vectorisée de l’algorithme a été utilisée (via numpy), permettant de traiter une ligne de pixels sous forme de vecteur.

## Résultats expérimentaux

| Méthode | Temps (4 processus) | Speedup (S) | Observations |
| :--- | :---: | :---: | :--- |
| Partition par blocs (Q1) | 0.368 s | 3.40 | Déséquilibre de charge marqué |
| Partition cyclique (Q2) | 0.348 s | 3.60 | Répartition améliorée, mais statique |
| Maître-esclave (Q3) | 0.186 s | 6.73 | Répartition dynamique efficace |

*\*Note : Le speedup super-linéaire (>4) est dû à l'utilisation conjointe de l'équilibrage dynamique et de la vectorisation (Numpy).*

## Interprétation

### 1. Équilibrage de charge
La stratégie dynamique permet d’éviter qu’un processus reste inactif tant que des tâches sont disponibles. Les lignes plus coûteuses sont compensées par le traitement simultané de lignes plus simples par les autres processus.

### 2. Effet de la vectorisation
Le temps d’exécution obtenu (0.186 s) est nettement inférieur à celui de la version séquentielle (1.253 s). Le speedup apparent dépasse la valeur attendue pour 4 cœurs (6.73 vs 4.0). Ce phénomène s’explique par l’amélioration de l’algorithme local : la vectorisation est plus efficace en termes d’accès mémoire et d’utilisation du processeur que l’implémentation pixel par pixel utilisée précédemment.

---

# Conclusion générale

Ce travail a permis de comparer trois stratégies de parallélisation appliquées au calcul de l’ensemble de Mandelbrot, caractérisé par une charge de calcul irrégulière.

- La partition par blocs est simple à mettre en œuvre, mais elle souffre d’un déséquilibre de charge important.
- La partition cyclique améliore la répartition du travail, mais reste sensible aux cas extrêmes et à l’hétérogénéité du matériel.
- La stratégie maître-esclave offre une solution plus robuste grâce à un équilibrage dynamique, au prix d’un surcoût de communication.

Pour des calculs dont le temps d’exécution est difficile à prévoir, une stratégie d’équilibrage dynamique est la plus adaptée. Combinée à des optimisations locales comme la vectorisation, elle permet d’obtenir des performances nettement supérieures.
